= Fence.t, a RISC-V extension proposal

== Why fence.t: the rationale

Covert channels use microarchitectural states to allow unauthorized communication across security boundaries.
Attackers can leverage these covert channel to leak data, from supervisor to user privilege levels, from one process to another, etc.
In particular, we are here interested in timing covert channels where the exfiltrated data is read through the timing of some operations.

Our threat model consider only timing covert channels since they can be leveraged on a distant device.
We consider other physic-based covert channels (e.g. using power consumption) as out of scope.

Covert channels are a critical part of transient execution attacks.
Such attacks typically use speculative execution to read a secret and then use a covert channel to exfiltrate the data.

*Any microarchitectural state*, no just cache memories, can support a covert channel and it is not realistically feasible to fordid microarchitectural state.
Since state sharing is a normal behaviour in most cases, the core requires a hint to know when state sharing is forbidden.
This is the purpose of _fence.t_.

== fence.t semantics 

This is a first draft proposal for _fence.t_.

We define the following RISC-V instruction, without source nor destination registers, but with optional flags.

[,asm]
----
fence.t [flags]
----

The flags may give precisions to the associated type of context switch related to this _fence.t_ when it applies.
The core must guarantee the following semantics.

[literal]
The timing of any instruction or sequence of instructions executing after the fence must be independent from any microarchitectural state before the fence. Exceptions may be occurs depending on the flags.

In this definition, timing is any measurable duration : we do not care if this is the actual duration of the execution of an instruction or if includes time spent in the issue queue, or something else.

Defined flags are the following:

- `PRIV_SWITCH`: the _fence.t_ is associated with a privilege level change.
- `AS_SWITCH`: the _fence.t_ is associated with a address space change.
- `INT_SWITCH`: the _fence.t_ is associated with an interrupt.

Any set of flags is valid. See <<section-split,Split section>> for precisions on how these flags may be used.

== Implementation guidelines



=== No timing dependecies

The first solution to enforce _fence.t_ semantics is to have instructions executing in a constant time fashion.
Typically arithmetic operations (usually excluding division and sometimes multiplication) are executed in constant time.

The RISC-V extension Zkt mandates execution in in data-independant manner for a given list of instructions.
*Our requirements here are different*.

We recognize that instruction execution time is a fuzzy concept on a modern complex microarchitecture: is it only the time spent in the execute stage ? Or does it comprise microarchitectural behaviours such as instruction scheduling ?

In our case, timings designate *any* measurable timings through _architectural_ means (with `RDTIME` for example). Timings measured through _physical_ means, such as power consumption measurements, are out of scope.


=== Flush

The most direct way to prevent microarchitectural state timing dependency is to erase the state.
Flushing is therefore in lots of case the go-to solution.
By flushing we mean that the corresponding state must be written to before any future use.

[example]
In the case of a simple data cache, flushing includes invalidating all data present. *But invalidation is not enough.* For example, extra-care must be taken to erase the cache invalidation mechanism metadata, so that future allocation is independant from the ones preceding the fence.

WARNING: Any microarchitectural state left intact accross _fence.t_ may still be used to support a covert channel.

What to flush is microarchitecture dependant.
But usually the biggest threats are with cache and branch predictions mechanisms.
But flushing can be costly, this is why, in some specific cases, we may prefer to split ressources instead.
Supporting _fence.t_ may imply microarchitectural changes. For example, for all its deficiencies, write-through caches are faster to invalidate than write-back.

[[section-split]]
=== Split

Some interfaces should requires a total microarchitectural flush but the cost of it is unmanageable.
This is typically the case for privilege levels switch, where some microarchitectural states such as branch predictor entries are indexed with the priviledged level.

Another such case are address spaces switching where we avoid to invalidate TLBs by indexing TLB entries with the Address Space IDentifier (ASID).
The TLB is effectively split into several subressources, one for each supported ASID.

In these cases, for these interfaces, _fence.t_ *may* avoid to flush the corresponding structures.
TLB entries donâ€™t need to be flushed when switching to a new address space, branch predictors when switching to a new privilege level.

This is the purpose of the flags that indicate that some microarchitectural state may *not* be flushed.

[example]
An application is performing a system call and the privilege level is switched to supervisor.
You want to prevent covert channel, but your core already have branch predictor states split by privilege level.
By flagging the switch as `fence.t PRIV_SWITCH`, the core can decide to not flush the branch predictor states.

=== Propagation to the bus / peripherals

Covert channels are not only supported by the core microarchitectural state.
The attacker can also use peripherals states, accessible and modifiable from the core, as such.
The simplest example is the last level cache (LLC), shared by all cores which can be used to create a covert channel.

The _fence.t_ semantics MUST be propagated to the core bus, to all peripherals so that they correctly deal with it.


=== Reorder barrier

With its semantics so defined, _fence.t_ imposes that out of order cores cannot reorder the fence *for instructions impacting the microarchitectural state*.
It is effectively a reorder barrier.


== Limits


=== Port contention

Port contention has been demonstrated to be the support of covert channels, in particular in multithreaded cores.
Notably, _fence.t_ does not solve this issue.
*And it can make it worse !*

Basically, the _fence.t_ can affect a shared cache and therefore, the other cores will have a cold cache state suddenly.
Allocation of execution time on cores sharing microarchitectural state must be security-conscious (independently of _fence.t_ in reality).

=== Fence.t timing variability

TODO constant time context switching: why / how
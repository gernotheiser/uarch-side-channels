# Meeting-3: 2022-04-19

## Topic 1: shared experiences with speculative execution vulnerabilities

Christian Ludloff

Share experience with microarchitecture and speculation vulnerabilities. Have spent a good deal of the past 5 years on these kinds of vulnerabilities.

We're 5 years in and are not seeing things getting really better. What we do see is that it's hard to get things right. The more we look into various chips, the more we keep finding, more bugs, more issues.

People make the same mistakes again and again. Which is not surprising, that's how humans are. It's difficult to get institutional memory, and so companies fall back on old behaviour. People change jobs, so chips improve for a while, and then repeat the same old errors. People start from the same RTL tree, repeating old mistakes.

People get disillusioned by the experience, because it seems like it isn't getting any better.


A few things have helped us in this rathole:
- For everything you build, make sure that there's an off button, registers and other ways of turning them off.
  * One very big one: microcode has saved the world again and again, dozens of cases where they were able to tell a chip to intercept things it was doing. As a tool to help get themselves out of holes. Some chips are designed without this, but even the simplest designs are finding the benefits.
  
- Something that does help: crystal clear models of what an architecture is doing, ability to grep the source, ability to do formal verification.

- When things are found in a particular chip: it's important to think about which other companies/ contributors/players could also be affected. Think bigger. Analogy: airlines, never point fingers that yours is more secure, when something happens ruthlessly investigate what happened and honestly report (blameless postmortem) .This can be a difficult thing in the industry, that kind of collaboration takes time to build, but can be immensely valuable.
  * Have designated contacts at the company for security reports. Some companies are small, and it's hard to dedicate resources. But even some big companies aren't really good at this.
  * Think outside your box and your chip. Most of the issues over the past 5 years totally transcend the architecture and the chip.
  * One good rule: always focus on the user. You're striving to make the world a better place, and helping your competitor helps your customer and your own company.
 
 
- In the notes from the last meeting, there was some discussion of approaches that divide the world into a more and less secure world. In real life, every instruction that you execute matters, otherwise you're in quite a lot of trouble.
  * Sure, you have an instruction that deals with decryption or password, but the results of that instruction have results and consequences more widely in the code. The secure comparison code has a boolean result that must be transmitted down the line.
  * Having a split between faster/more secure does not work, you're pushing the decision to users who may not even be qualified to make the choice. The user wants it to be both faster and more secure.
  * In real life performance is a painful factor.
 
- When you ship, people think a chip will stay in the market for a few years. Really, it's more like 10, 15, 20 years. Worst case is even worse than that.
   * "Fix in version 2" may never happen.
  
  
- Sometimes an issue comes along and people say "hey, can you just turn it off". For example, you add a bunch of new branch predictors, and find vulnerabilities in them after you ship. The response is almost always "no, we didn't put in an off button", and you're stuck with the vulnerabilities.
   * Off buttons can be complicated, there are so many, and often untested.
   * Having your chip have lots of safety things can be problematic. Analogy: your car has lots of features you don't even realize, and the mechanic shows you all kinds of things you can turn on. But there will always be that one thing where the one thing the mechanic has no control to turn it on or off.
  
- We've had the pipe dream from various different companies over the years, a magic bit that turns off all speculation or operates in a "speculation safe mode". But, in the end, they have never shipped it.
   * A practical outcome, what has happened: people have microcode to roll out and fix a bug. Between the pressure of being correct versus 2% performance gain, the higher-level decision is in favor of the 2% performance gains. Lengthy arguments follow about why they think they're safe from the particular attack.
   * It surprises the chip vendors too. We gave you this fix, why are you not using it.
  
Questions:
- There are many types of side-channel attacks, each mitigation has its own performance penalty. Open question, how much of the mitigations do get turned on, and how much don't?
  * Christian: You've put the finger on the point there. We've had really horrible cases as well. We have no knobs, we have to do it in software with 5000 branch instructions. It turns out to have a 98% performance penalty, and it's unshippable. We have chips that have become unusable in real life.
  * In the client market, where chips might not be so beefy, low margins on the minimum you can get by on for browser and video conferencing. Some laptops with today's mitigations simply can't run video calls anymore, even though they could before.
  * There is no good general rule when we will take a mitigation, when we won't. No, there's no good magic to solve the speculative execution vulnerabilities with a low performance penalty like 4.9%.
 

- Side channels aren't your only problem, security takes many forms.
   * Row hammer has been a very painful one in recent times.
   * Another equally challenging for the industry: silent data corruption (SDC), at scale 1+1 is not always 2, with enough machines over enough cycles, statistically it comes out wrong, none of the RAS completely fixes the problem. (Example: one specific core on one specific machine did AES wrong, and a user account created on one core, wasn't readable once it moved to another core.)


- What arch/uarch features do you depend on to secure the systems software stack? [topic for future discussion]

- What arch/uarch features do you wish you had?
  * Whenever you can, reduce complexity don't grow it, because the complexity keeps piling on. May squeeze out a 1% performance gain, but if it breaks later and costs you $5 million, it's not worth it. Did you have to make the branch predictor this smart? It didn't help you in the long run. Engineering goes further than "my boss told me to make it this fast", it's about making life better in the long run.

On every context switch, you going to flush state? Enormous cost.

ARM is adding microcode, perspective has changed.

Open source: openness is great for the ability look at things, but it's not a guarantee. People go for the cheapest way forward, which doesn't always include doing the work to improve things.

There is no easy way out, this is engineering, if it's built well it serves people's needs. There's always a compromise.

If you make a chip, you will run into this problem.

We had these firmly held beliefs, turned out to be wrong. The instruction says "don't ever do that", but people will.

With this ecosystem, it's particularly hard because there is no central location. This working group may be a good place to report that, and handle that. Security response team. Have struggled with this, have you briefed all the vendors. There is a security response team in RISC-V. It's part of the security horizontal committee.


## Topic 2: Cross-SIG sync with new Memory Safety SIG

In 10 minutes, informal chat with memory safety sig about what we may need.
Suggest memory safety annotation, when should we disable speculative loads.

We are still waiting for the memory safety SIG to get started, we want to move some pending proposals from the TEE TG to other SIGs.

One of the things we've discussed for Confidential Compute, is that we needed a way to track pages that belong to the TEE, and which don't. It's a mechanism we want to have. Once we're done with it on the hart-side, may do something on the IOMMU-side.

We also have the J extension, which is pointer masking, we expect this to evolve to verify memory tags in hardware.

CFI task group are working on the shadow stack, and need a way to protect the shadow stack from loads and stores.

Linux kernel is evolving a concept of confidential memory. There is [a mmap flag](https://lwn.net/Articles/865256/), those pages will be donated by the kernel, not visible even to debug. (Pure software, pages are in the kernel space. When you switch to the application, they are made available, but when you're in kernel space they don't exist.) Maybe if we had a flag disabling speculative loads and stores, adding an annotation for marking regions as protected from speculation, it could be mapped to Linux.

Christian: observation, everybody wants metabits that have some particular meaning. At scale the cost of those metabits add up. Every load/store has to walk extra levels for permissions.


Backlog topics from the TEE group: Don't have a constant trap delivery on riscv, on ARM they have a bit for that, that helps mitigate against KASLR. A way of bypassing KASLR, a way of guaranteeing that traps are delivered in constant time. Evolving the constant time requirements from the crypto group as well.
